## 数据同步

分析业务系统的数据，一种简单的操作方式是直接访问业务系统的数据库，如下图所示：

![直接访问数据库][1]

业务系统和数据分析应用依赖同一个数据库，数据库既要处理OLTP事务型操作（如线上的用户请求），又要处理OLAP的查询（如离线数据分析）。

两种业务使用同一个数据库的优点是可以保证数据的实时性，业务系统产生的数据变化可以立即反馈到OLAT的查询中，没有任何数据延迟。

这种框架的缺点也十分明显，数据库同时要处理两种业务需求，会产生额外的压力，进而影响线上业务的服务质量，就是因为又这个缺点，这个框架在生产环境中很少使用。

## 主从复制框架

为克服多种业务直接访问同一个数据库引起的问题，避免线上业务和数据分析业务在数据库层面的互相影响，一般会使用下面这种数据同步框架：

![主从复制][2]

在线应用服务访问数据库的Master节点，数据分析服务访问数据库的Slave节点，Master和Slave之间使用主从同步的方式保证数据的一致性，这种系统可以保证在不影响线上系统的情况下进行数据的实时分析业务。

该框架的核心在于主从同步，那么主从同步的原理是什么？

以MySQL为例，每条数据库操作请求都会记录在binlog中，操作请求的时间、操作的表、修改的字段值等信息都会被记录下来，从节点Slave只要拿到了Master节点的binlog，就可以按Master节点的操作对Slave节点重复进行一次数据库的相同操作，等于将Master节点的数据库复制了一份到从节点。

这个框架解决了在线和离线不同业务系统相互影响的问题，但是所查询的数据还是仅限于某个应用系统中，未能实现不同服务的数据打通，生成统一的数据视图，所以该框架还不能完全满足数据分析师的需求，也就是数据孤岛问题。

## 传统数据仓库

Hadoop出现之前，为解决数据孤岛问题，需要使用传统的数据仓库工具和聚合业务工具来解决。

![传统数据仓库][3]

MySql、Oracle数据库的数据需要先通过ETL清洗、聚合，导入到数据仓库服务中，然后数据仓库作为统一数据源，直接对接报表系统、数据挖掘、数据分析等服务。

传统数据仓库服务包括 [Teradata][4] 、 [ODS][5] 等，他们都提供了SQL语法支持，学习门槛较低。另外还支持JDBC、ODBC连接，接入也比较方便。这使得当时数据仓库变得十分流行。

传统数据仓库相对于现在使用场景来说也有自己的缺点：

- 是闭源系统，代码不公开，定位和解决问题比较困难，只能依赖文档，有很大的局限性。有BUG只能等待官方修复。

- 成本昂贵，部署和服务支持的费用都很高。

- 扩容复杂，集群上限较低。

- 性能有瓶颈，比如社交推荐可能认识好友的场景，随着用户数量的增长，由于扩容复杂，集群计算能力越来越难以满足要求。

Hadoop不存在这样的问题，所以打通传统数据仓库与Hadoop之间的数据流动就变得非常有必要。



[1]: https://github.com/jiaoqiyuan/163-bigdate-note/raw/master/%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%9ASqoop/img/%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE%E6%95%B0%E6%8D%AE%E5%BA%93.png
[2]: https://github.com/jiaoqiyuan/163-bigdate-note/raw/master/%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%9ASqoop/img/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%BC%8F.png
[3]: https://github.com/jiaoqiyuan/163-bigdate-note/raw/master/%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%9ASqoop/img/%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93.png
[4]: https://baike.baidu.com/item/Teradata
[5]: https://zh.wikipedia.org/wiki/ODS