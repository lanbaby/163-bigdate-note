> 这里将会讲解Sqoop是怎么尽量在MapReduce中均衡的切分数据的

下面说的导入和导出都是针对HDFS来说，也即导入是指向HDFS到处数据，导出是指从HDFS导出数据。

## 数据导入

现有一个Order表，需要将其数据导入到HDFS上，主键是id。如下图所示：

![Sqoop导入][1]

Sqoop在解析完命令参数后会查找参数指定的分片字段的数据范围，假设用户指定的分片字段为id，通过jdbc接口可以找到id的最大值和最小值，分别是5000和1。

数据范围除以map数量可以得到每个Map传输的数据id范围，假设map数是5个，那么每个map的范围就是5000/5=1000，如上图所示。每个map使用SQL语句进行筛选，筛选方法就是在SQL中添加where条件，比如第一个map的where条件就可以写为id >= 1 and id <= 1000。

每个map都会在HDFS上生成一个对应的文件，存储向HDFS导入的数据。

## 数据导出

数据导出跟导入正好相反，是把HDFS上的文件导出到数据库中，过程如下图所示：

![Sqoop导出][2]

导出任务的数据划分完全依赖于HDFS的 `FileInputFormat` 的 split 划分，默认情况下会使用 `CombineInputFormat` ，尽量把同一个节点的数据使用同一个map来处理，这样可以众多小文件导致的创建map任务的开销，提高任务的执行效率。

但是如果导出的数据文件是压缩格式，且这种压缩格式不能再分片，那么文件就会当以单个文件进行分片，每一个文件会生成一个map进行导出。

导出任务的分片逻辑比较复杂，用户指定的并发参数往往不会生效。

## 总结

Sqoop是基于MapReduce框架的数据同步工具，启用多个map进行数据的并发导入和导出。对于导入任务，数据的分片是基于数据中数据的范围和用户指定的并发数；对于导出任务，数据分片是依赖HDFS的 `FileInputFormat` 的分片策略。

[1]: https://github.com/jiaoqiyuan/163-bigdate-note/raw/master/%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%9ASqoop/img/Sqoop%E5%AF%BC%E5%85%A5.png
[2]: https://github.com/jiaoqiyuan/163-bigdate-note/raw/master/%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%9ASqoop/img/Sqoop%E5%AF%BC%E5%87%BA.png